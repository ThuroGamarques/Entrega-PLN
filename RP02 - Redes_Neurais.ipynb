{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo de Rede Neural de Recorrência"
      ],
      "metadata": {
        "id": "lYTI8yriSYT2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passo 1: Configuração do Ambiente no Google Colab"
      ],
      "metadata": {
        "id": "TcPDCODFNfC0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auo7TL_TNBQ_",
        "outputId": "69965045-c3c2-45c7-dfea-39953c474322"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bibliotecas importadas com sucesso!\n"
          ]
        }
      ],
      "source": [
        "# Importar bibliotecas necessárias\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "print (\"Bibliotecas importadas com sucesso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passo 2: Preparação do Conjunto de Dados"
      ],
      "metadata": {
        "id": "4BW7_GYaOBzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conjunto de dados de treinamento (pequeno e simplificado)\n",
        "textos_treinamento = [\n",
        "    \"eu gosto de programar em python\",\n",
        "    \"python é uma linguagem poderosa\",\n",
        "    \"programar é divertido com python\",\n",
        "    \"aprenda python e seja feliz\",\n",
        "    \"gosto de aprender coisas novas\"\n",
        "]\n",
        "print(f\"Textos de treinamento: {textos_treinamento}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDp5vS4CODzJ",
        "outputId": "46cb53a2-516e-48e4-e923-4e3041be5524"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Textos de treinamento: ['eu gosto de programar em python', 'python é uma linguagem poderosa', 'programar é divertido com python', 'aprenda python e seja feliz', 'gosto de aprender coisas novas']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar o Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Construir o vocabulário a partir dos textos\n",
        "tokenizer.fit_on_texts(textos_treinamento)\n",
        "\n",
        "# Converter textos em sequências de números\n",
        "sequencias = tokenizer.texts_to_sequences(textos_treinamento)\n",
        "\n",
        "# Imprimir o vocabulário e as sequências geradas\n",
        "print(f\"\\nVocabulário (palavra: índice): {tokenizer.word_index}\")\n",
        "print(f\"Sequências numéricas dos textos: {sequencias}\")\n",
        "\n",
        "# Calcular o tamanho do vocabulário (+1 para incluir o 0 de padding)\n",
        "total_palavras = len(tokenizer.word_index) + 1\n",
        "print(f\"Tamanho total do vocabulário: {total_palavras}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_9Gtb3KOXAZ",
        "outputId": "2f95acfb-2934-441b-9111-72dc152e0cc8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vocabulário (palavra: índice): {'python': 1, 'gosto': 2, 'de': 3, 'programar': 4, 'é': 5, 'eu': 6, 'em': 7, 'uma': 8, 'linguagem': 9, 'poderosa': 10, 'divertido': 11, 'com': 12, 'aprenda': 13, 'e': 14, 'seja': 15, 'feliz': 16, 'aprender': 17, 'coisas': 18, 'novas': 19}\n",
            "Sequências numéricas dos textos: [[6, 2, 3, 4, 7, 1], [1, 5, 8, 9, 10], [4, 5, 11, 12, 1], [13, 1, 14, 15, 16], [2, 3, 17, 18, 19]]\n",
            "Tamanho total do vocabulário: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparar Entradas (X) e Saídas (y) para a previsão da próxima palavra\n",
        "# a entrada (X) será uma sequência de palavras, e a saída (y) será a palavra seguinte.\n",
        "# Determinar o comprimento máximo das sequências para padding\n",
        "max_comprimento = max(len(seq) for seq in sequencias)\n",
        "print(f\"\\nComprimento máximo das sequências antes do padding: {max_comprimento}\")\n",
        "\n",
        "# Criar pares de entrada (sequência parcial) e saída (próxima palavra)\n",
        "# Ex: \"eu gosto de programar\" -> \"em\"\n",
        "#     \"gosto de programar em\" -> \"python\"\n",
        "entradas_X = []\n",
        "saidas_y = []\n",
        "for seq in sequencias:\n",
        "    for i in range(1, len(seq)):\n",
        "        entradas_X.append(seq[:i]) # A sequência até a palavra atual\n",
        "        saidas_y.append(seq[i])    # A próxima palavra\n",
        "\n",
        "print(f\"Exemplo de entradas_x (parcial): {entradas_X[0:5]}\")\n",
        "print(f\"Exemplo de entradas_x (parcial): {saidas_y[0:5]}\")\n",
        "\n",
        "# Padronizar o comprimento das sequências de entrada\n",
        "# Todas as sequências de entrada precisam ter o mesmo comprimento para a RNN\n",
        "entradas_x_padded = pad_sequences(entradas_X, maxlen=max_comprimento -1, padding='pre')\n",
        "# O maxlen é \"max_comprimento - 1\" por que a saída \"y\" é a última palavra, então X sempre terá 1 palavra a menos.\n",
        "\n",
        "# Converter as saídas para o formato one-hot encoding\n",
        "# Isso é necessário para a camada de saída de RNN (softmax)\n",
        "saidas_y_one_hot = tf.keras.utils.to_categorical(saidas_y, num_classes=total_palavras)\n",
        "\n",
        "print(f\"\\nExemplo de entradas_X_padded (após padding e truncagem): \\n{entradas_x_padded[0:5]}\")\n",
        "print(f\"Exemplo de saídas_y_one_hot (após one-hot encoding): \\n{saidas_y_one_hot[0:5]}\")\n",
        "print(f\"Formato final das entradas (X): {entradas_x_padded.shape}\")\n",
        "print(f\"Formato final das saídas (y): {saidas_y_one_hot.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Uj9T1HDPAON",
        "outputId": "1d84dafd-bdab-45df-fb0a-3ef9c7bb33fb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comprimento máximo das sequências antes do padding: 6\n",
            "Exemplo de entradas_x (parcial): [[6], [6, 2], [6, 2, 3], [6, 2, 3, 4], [6, 2, 3, 4, 7]]\n",
            "Exemplo de entradas_x (parcial): [2, 3, 4, 7, 1]\n",
            "\n",
            "Exemplo de entradas_X_padded (após padding e truncagem): \n",
            "[[0 0 0 0 6]\n",
            " [0 0 0 6 2]\n",
            " [0 0 6 2 3]\n",
            " [0 6 2 3 4]\n",
            " [6 2 3 4 7]]\n",
            "Exemplo de saídas_y_one_hot (após one-hot encoding): \n",
            "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "Formato final das entradas (X): (21, 5)\n",
            "Formato final das saídas (y): (21, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passo 3: Construção do Modelo RNN"
      ],
      "metadata": {
        "id": "fiNCz_toRpgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Definindo o modelo\n",
        "# Definir a arquitetura do modelo RNN\n",
        "modelo_rnn = Sequential()\n",
        "\n",
        "# Camada de Embedding:\n",
        "# total_palavras: tamanho do vocabulário\n",
        "# 10: dimensão do vetor de embedding (quantas características queremos para cada palavra)\n",
        "# input_length: comprimento das sequências de entrada (maxlen - 1)\n",
        "modelo_rnn.add(Embedding(total_palavras, 10, input_length=entradas_x_padded.shape[1]))\n",
        "\n",
        "# Camada SimpleRNN:\n",
        "# 32: número de unidades (neurônios) na camada recorrente. Este é o tamanho do estado oculto.\n",
        "modelo_rnn.add(SimpleRNN(32))\n",
        "\n",
        "# Camada Densa de Saída:\n",
        "# total_palavras: número de neurônios de saída (um para cada palavra no vocabulário)\n",
        "# activation='softmax': função de ativação para probabilidade (soma 1 para todas as palavras)\n",
        "modelo_rnn.add(Dense(total_palavras, activation='softmax'))\n",
        "\n",
        "# Compilar o modelo\n",
        "modelo_rnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Exibir um resumo da arquitetura do modelo\n",
        "modelo_rnn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "mgft2BsFRPsP",
        "outputId": "d938ea04-5c61-4e92-907e-0d2c808db9eb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passo 4: Treinamento do Modelo"
      ],
      "metadata": {
        "id": "_CilSmmMRz3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinando o modelo\n",
        "print(\"\\nIniciando o treinamento do modelo RNN...\")\n",
        "modelo_rnn.fit(entradas_x_padded, saidas_y_one_hot, epochs=100, verbose=1)\n",
        "    # epochs: quantas vezes o modelo verá todo o conjunto de dados\n",
        "    # verbose: 1 para mostrar o progresso do treinamento\n",
        "print(\"Treinamento concluído\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxRhNGh0R1qL",
        "outputId": "4c9f5e48-2d4b-42be-a5ad-af87d3fb5f9c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando o treinamento do modelo RNN...\n",
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: 2.9946\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.0000e+00 - loss: 2.9858\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.0476 - loss: 2.9770\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.0952 - loss: 2.9680\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.0952 - loss: 2.9588\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.1429 - loss: 2.9493\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.1905 - loss: 2.9396\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.1905 - loss: 2.9294\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.1905 - loss: 2.9189\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.1905 - loss: 2.9079\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.1905 - loss: 2.8964\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.1905 - loss: 2.8845\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.1905 - loss: 2.8721\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.1905 - loss: 2.8592\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.1905 - loss: 2.8458\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.1905 - loss: 2.8320\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.1905 - loss: 2.8177\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.1429 - loss: 2.8032\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.1905 - loss: 2.7885\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.1905 - loss: 2.7738\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.1429 - loss: 2.7591\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.1429 - loss: 2.7446\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.1429 - loss: 2.7304\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.1429 - loss: 2.7167\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.1429 - loss: 2.7034\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.1429 - loss: 2.6906\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.1429 - loss: 2.6780\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.1429 - loss: 2.6656\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.1429 - loss: 2.6532\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.1429 - loss: 2.6405\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.1429 - loss: 2.6274\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.1429 - loss: 2.6137\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.1429 - loss: 2.5993\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.1429 - loss: 2.5841\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.1429 - loss: 2.5682\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.1429 - loss: 2.5516\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.1429 - loss: 2.5342\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.1905 - loss: 2.5162\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.2857 - loss: 2.4975\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.2857 - loss: 2.4782\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.2857 - loss: 2.4581\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.2857 - loss: 2.4373\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.2381 - loss: 2.4158\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.2857 - loss: 2.3935\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.3333 - loss: 2.3704\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.3333 - loss: 2.3465\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.3333 - loss: 2.3219\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.3810 - loss: 2.2967\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.3810 - loss: 2.2708\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.3810 - loss: 2.2444\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.3333 - loss: 2.2175\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.3810 - loss: 2.1902\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.3810 - loss: 2.1626\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.3810 - loss: 2.1348\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.3810 - loss: 2.1069\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.3810 - loss: 2.0790\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.3810 - loss: 2.0512\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.4286 - loss: 2.0234\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.4286 - loss: 1.9959\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.4286 - loss: 1.9685\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.4286 - loss: 1.9413\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.4286 - loss: 1.9144\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.4286 - loss: 1.8878\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4286 - loss: 1.8614\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.4286 - loss: 1.8354\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.4286 - loss: 1.8096\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.4762 - loss: 1.7843\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.5238 - loss: 1.7593\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.5714 - loss: 1.7347\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.5714 - loss: 1.7105\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.5714 - loss: 1.6866\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5714 - loss: 1.6632\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6190 - loss: 1.6402\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6190 - loss: 1.6176\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6190 - loss: 1.5953\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.6190 - loss: 1.5735\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.6190 - loss: 1.5521\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6190 - loss: 1.5310\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6190 - loss: 1.5103\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6190 - loss: 1.4900\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6190 - loss: 1.4700\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6667 - loss: 1.4504\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6667 - loss: 1.4311\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6667 - loss: 1.4121\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7143 - loss: 1.3935\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7143 - loss: 1.3751\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7143 - loss: 1.3571\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7143 - loss: 1.3393\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7143 - loss: 1.3218\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7143 - loss: 1.3046\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7143 - loss: 1.2877\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7143 - loss: 1.2710\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7619 - loss: 1.2546\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7619 - loss: 1.2384\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7619 - loss: 1.2224\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7619 - loss: 1.2067\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7619 - loss: 1.1911\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7619 - loss: 1.1758\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7619 - loss: 1.1607\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7619 - loss: 1.1458\n",
            "Treinamento concluído\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passo 5: Usar o Modelo para Previsão"
      ],
      "metadata": {
        "id": "VIemCvJTSIgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Função de Previsão:\n",
        "def prever_proxima_palavra(modelo, tokenizer, max_seq_len, texto_base):\n",
        "    \"\"\"\n",
        "    Prevê a próxima palavra dado um texto base.\n",
        "    \"\"\"\n",
        "    # Converter o texto base para sequência numérica\n",
        "    sequencia_numerica = tokenizer.texts_to_sequences([texto_base])[0]\n",
        "\n",
        "    # Padronizar o comprimento da sequência de entrada (precisa ter o mesmo formato que o treinamento)\n",
        "    # Atenção: max_seq_len deve ser o comprimento que as *entradas* foram pad_sequenciadas\n",
        "    sequencia_padded = pad_sequences([sequencia_numerica], maxlen=max_seq_len, padding='pre')\n",
        "\n",
        "    # Fazer a previsão\n",
        "    previsao_probabilidades = modelo.predict(sequencia_padded, verbose=0)[0]\n",
        "\n",
        "    # Obter o índice da palavra com a maior probabilidade\n",
        "    indice_palavra_prevista = np.argmax(previsao_probabilidades)\n",
        "\n",
        "    # Converter o índice de volta para a palavra\n",
        "    for palavra, indice in tokenizer.word_index.items():\n",
        "        if indice == indice_palavra_prevista:\n",
        "            return palavra\n",
        "\n",
        "    return None  # Caso a palavra não seja encontrada (improvável com o vocabulário ajustado)\n",
        "\n",
        "# Comprimento de entrada esperado pelo modelo\n",
        "# entradas_X_padded.shape[1] é o maxlen que usamos no pad_sequences para X\n",
        "comprimento_entrada_modelo = entradas_x_padded.shape[1]\n",
        "\n",
        "# Testar o modelo com novas frases\n",
        "print(\"\\n--- Testando o Modelo RNN ---\\n\")\n",
        "\n",
        "texto_teste_1 = \"eu gosto de\"\n",
        "proxima_1 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_1)\n",
        "print(f\"Texto: '{texto_teste_1}' -> Próxima palavra prevista: '{proxima_1}'\")\n",
        "\n",
        "texto_teste_2 = \"python é uma\"\n",
        "proxima_2 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_2)\n",
        "print(f\"Texto: '{texto_teste_2}' -> Próxima palavra prevista: '{proxima_2}'\")\n",
        "\n",
        "texto_teste_3 = \"programar é divertido\"\n",
        "proxima_3 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_3)\n",
        "print(f\"Texto: '{texto_teste_3}' -> Próxima palavra prevista: '{proxima_3}'\")\n",
        "\n",
        "texto_teste_4 = \"aprenda python e\"\n",
        "proxima_4 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_4)\n",
        "print(f\"Texto: '{texto_teste_4}' -> Próxima palavra prevista: '{proxima_4}'\")\n",
        "\n",
        "# Exemplo com palavra fora do vocabulário (ou sequência que o modelo nunca viu antes)\n",
        "texto_teste_5 = \"o sol brilha no\"\n",
        "# \"o\", \"sol\" e \"brilha\" não estão no vocabulário\n",
        "proxima_5 = prever_proxima_palavra(modelo_rnn, tokenizer, comprimento_entrada_modelo, texto_teste_5)\n",
        "print(f\"Texto: '{texto_teste_5}' -> Próxima palavra prevista: '{proxima_5}' (Pode ser inesperada devido a palavras desconhecidas)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcnGNUUSSLQ3",
        "outputId": "b6dd472e-58c6-4166-f675-daccca2ff812"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testando o Modelo RNN ---\n",
            "\n",
            "Texto: 'eu gosto de' -> Próxima palavra prevista: 'programar'\n",
            "Texto: 'python é uma' -> Próxima palavra prevista: 'linguagem'\n",
            "Texto: 'programar é divertido' -> Próxima palavra prevista: 'com'\n",
            "Texto: 'aprenda python e' -> Próxima palavra prevista: 'seja'\n",
            "Texto: 'o sol brilha no' -> Próxima palavra prevista: 'é' (Pode ser inesperada devido a palavras desconhecidas)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo de Rede Neural Long Short-Term Memory"
      ],
      "metadata": {
        "id": "xYkiMz6_SUHO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passo 1: Configuração do Ambiente e Importação de Bibliotecas"
      ],
      "metadata": {
        "id": "ncUPZUriSqsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar bibliotecas necessárias\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"Bibliotecas Importadas com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgZx-ac5SqIM",
        "outputId": "c9605b59-1204-4766-8f57-e196ca0f9b5e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bibliotecas Importadas com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passo 2: Preparação do Conjunto de Dados de Análise de Sentimentos"
      ],
      "metadata": {
        "id": "AEFm0oQ8TKE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Definir o Conjunto de Dados (Frases e Rótulos) para análise de sentimentos\n",
        "dados_sentimento = [\n",
        "    (\"este filme é ótimo e divertido\", \"positivo\"),\n",
        "    (\"Adorei muito, muito bom!\", \"positivo\"),\n",
        "    (\"foi uma ótima atuação dos atores\", \"positivo\"),\n",
        "    (\"o roteiro é fraco e chato\", \"negativo\"),\n",
        "    (\"Gostei do enredo, mas não do produto\", \"negativo\"),\n",
        "    (\"uma perda de tempo horrível\", \"negativo\"),\n",
        "    (\"filme terrível, inacabável\", \"negativo\"),\n",
        "    (\"Não gostei de nenhum dos finais\", \"negativo\"),\n",
        "    (\"excelente serviço, muito eficiente\", \"positivo\"),\n",
        "    (\"decepcionante, muito ruim\", \"negativo\"),\n",
        "    (\"personagem cativante e emocionante\", \"positivo\"),\n",
        "    (\"O plano de fundo é interessante\", \"positivo\"),\n",
        "    (\"péssima qualidade várias vezes\", \"negativo\"),\n",
        "    (\"interface é confusa e difícil\", \"negativo\"),\n",
        "    (\"serviço super útil e rápido\", \"positivo\")\n",
        "]\n",
        "\n",
        "textos = [dado[0] for dado in dados_sentimento]\n",
        "sentimentos = [dado[1] for dado in dados_sentimento]\n",
        "\n",
        "print(f\"Total de frases: {len(textos)}\")\n",
        "print(f\"Exemplo de textos: {textos[:3]}\")\n",
        "print(f\"Exemplo de sentimentos: {sentimentos[:3]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDBfsJjiTOkd",
        "outputId": "b678e955-2493-4306-d9bc-f08440a870cd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de frases: 15\n",
            "Exemplo de textos: ['este filme é ótimo e divertido', 'Adorei muito, muito bom!', 'foi uma ótima atuação dos atores']\n",
            "Exemplo de sentimentos: ['positivo', 'positivo', 'positivo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Mapear Sentimentos para Números: converter \"positivo\" e \"negativo\" para 0 e 1.\n",
        "mapeamento_sentimento = {'negativo': 0, 'positivo': 1}\n",
        "rotulos_numericos = np.array([mapeamento_sentimento[s] for s in sentimentos])\n",
        "\n",
        "print(f\"\\nSentimentos mapeados para números: {rotulos_numericos}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVNaN1voTfIS",
        "outputId": "baea8b6c-6315-4f3f-e4d3-8c0ac7cd07f9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentimentos mapeados para números: [1 1 1 0 0 0 0 0 1 0 1 1 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Tokenização do Texto\n",
        "tokenizer = Tokenizer(num_words=None, oov_token=\"<unk>\")\n",
        "# num_words=None para pegar todo o vocabulário\n",
        "# oov_token para palavras desconhecidas\n",
        "tokenizer.fit_on_texts(textos)\n",
        "sequencias_numericas = tokenizer.texts_to_sequences(textos)\n",
        "\n",
        "total_palavras_vocab = len(tokenizer.word_index) + 1 # +1 para o 0 de padding/OOV\n",
        "\n",
        "print(f\"\\nVocabulário (palavra: índice): {tokenizer.word_index}\")\n",
        "print(f\"Sequências numéricas das frases: {sequencias_numericas}\")\n",
        "print(f\"Tamanho total do vocabulário: {total_palavras_vocab}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi7LSWrfThAi",
        "outputId": "d599880e-afea-416e-9d47-6577de06a442"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vocabulário (palavra: índice): {'<unk>': 1, 'e': 2, 'é': 3, 'muito': 4, 'de': 5, 'filme': 6, 'uma': 7, 'dos': 8, 'o': 9, 'gostei': 10, 'do': 11, 'não': 12, 'serviço': 13, 'este': 14, 'ótimo': 15, 'divertido': 16, 'adorei': 17, 'bom': 18, 'foi': 19, 'ótima': 20, 'atuação': 21, 'atores': 22, 'roteiro': 23, 'fraco': 24, 'chato': 25, 'enredo': 26, 'mas': 27, 'produto': 28, 'perda': 29, 'tempo': 30, 'horrível': 31, 'terrível': 32, 'inacabável': 33, 'nenhum': 34, 'finais': 35, 'excelente': 36, 'eficiente': 37, 'decepcionante': 38, 'ruim': 39, 'personagem': 40, 'cativante': 41, 'emocionante': 42, 'plano': 43, 'fundo': 44, 'interessante': 45, 'péssima': 46, 'qualidade': 47, 'várias': 48, 'vezes': 49, 'interface': 50, 'confusa': 51, 'difícil': 52, 'super': 53, 'útil': 54, 'rápido': 55}\n",
            "Sequências numéricas das frases: [[14, 6, 3, 15, 2, 16], [17, 4, 4, 18], [19, 7, 20, 21, 8, 22], [9, 23, 3, 24, 2, 25], [10, 11, 26, 27, 12, 11, 28], [7, 29, 5, 30, 31], [6, 32, 33], [12, 10, 5, 34, 8, 35], [36, 13, 4, 37], [38, 4, 39], [40, 41, 2, 42], [9, 43, 5, 44, 3, 45], [46, 47, 48, 49], [50, 3, 51, 2, 52], [13, 53, 54, 2, 55]]\n",
            "Tamanho total do vocabulário: 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Padronizar o comprimento das sequências\n",
        "# Encontrar o comprimento da frase mais longa para padronizar\n",
        "max_len = max([len(s) for s in sequencias_numericas])\n",
        "print(f\"\\nComprimento máximo das sequências: {max_len}\")\n",
        "\n",
        "entradas_X_padded = pad_sequences(sequencias_numericas, maxlen=max_len, padding='post') # 'post' para adicionar zeros no final\n",
        "print(f\"Sequências após padding: \\n{entradas_X_padded}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vmypc0ezTjFk",
        "outputId": "af99e3e1-bf14-40ec-939e-d5cca3f07ef2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comprimento máximo das sequências: 7\n",
            "Sequências após padding: \n",
            "[[14  6  3 15  2 16  0]\n",
            " [17  4  4 18  0  0  0]\n",
            " [19  7 20 21  8 22  0]\n",
            " [ 9 23  3 24  2 25  0]\n",
            " [10 11 26 27 12 11 28]\n",
            " [ 7 29  5 30 31  0  0]\n",
            " [ 6 32 33  0  0  0  0]\n",
            " [12 10  5 34  8 35  0]\n",
            " [36 13  4 37  0  0  0]\n",
            " [38  4 39  0  0  0  0]\n",
            " [40 41  2 42  0  0  0]\n",
            " [ 9 43  5 44  3 45  0]\n",
            " [46 47 48 49  0  0  0]\n",
            " [50  3 51  2 52  0  0]\n",
            " [13 53 54  2 55  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Dividir os dados em conjuntos de treinamento e teste\n",
        "X_treino, X_teste, y_treino, y_teste = train_test_split(\n",
        "    entradas_X_padded, rotulos_numericos, test_size=0.2, random_state=42, stratify=rotulos_numericos\n",
        ")\n",
        "\n",
        "print(f\"\\nShape de X_treino: {X_treino.shape}\")\n",
        "print(f\"Shape de X_teste: {X_teste.shape}\")\n",
        "print(f\"Shape de y_treino: {y_treino.shape}\")\n",
        "print(f\"Shape de y_teste: {y_teste.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K45Hq4GITk0c",
        "outputId": "4df786f7-248d-4fa9-b1c4-7e94d5048937"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape de X_treino: (12, 7)\n",
            "Shape de X_teste: (3, 7)\n",
            "Shape de y_treino: (12,)\n",
            "Shape de y_teste: (3,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passo 3: Construção do Modelo LSTM"
      ],
      "metadata": {
        "id": "SB6tiRuJTm0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir a arquitetura do modelo LSTM\n",
        "modelo_lstm = Sequential()\n",
        "\n",
        "# Camada de Embedding: Converte os índices numéricos das palavras em vetores densos.\n",
        "# total_palavras_vocab: tamanho do vocabulário\n",
        "# 50: dimensão do vetor de embedding (pode ser ajustado)\n",
        "# input_length: comprimento padronizado das sequências (max_len)\n",
        "modelo_lstm.add(Embedding(total_palavras_vocab, 50, input_length=max_len))\n",
        "\n",
        "# Camada LSTM:\n",
        "# 64: número de unidades (neurônios) na camada LSTM. Define o tamanho do estado oculto e da célula de memória.\n",
        "# dropout: Um tipo de regularização para evitar overfitting (descarta aleatoriamente neurônios durante o treinamento).\n",
        "# recurrent_dropout: Dropout aplicado nas conexões recorrentes da LSTM.\n",
        "modelo_lstm.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
        "\n",
        "# Camada Densa de Saída:\n",
        "# 1: Um único neurônio de saída, pois é um problema de classificação binária (positivo/negativo).\n",
        "# activation='sigmoid': Função de ativação para classificação binária (produz um valor entre 0 e 1).\n",
        "modelo_lstm.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compilar o modelo\n",
        "modelo_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Exibir um resumo da arquitetura do modelo\n",
        "modelo_lstm.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "Jr-49UO6TsIi",
        "outputId": "c6517835-b33b-433b-ac08-9792012e5393"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passo 4: Treinamento e Avaliação do Modelo"
      ],
      "metadata": {
        "id": "HoLglK29TsQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo\n",
        "print(\"\\nIniciando o treinamento do modelo LSTM...\")\n",
        "historico = modelo_lstm.fit(\n",
        "    X_treino, y_treino,\n",
        "    epochs=50, # Reduzi para 50 epochs para um treinamento mais rápido no exemplo. Pode ser aumentado.\n",
        "    batch_size=2, # Pequeno batch_size para dataset pequeno.\n",
        "    validation_split=0.1, # Usar 10% do treino para validação\n",
        "    verbose=1\n",
        ")\n",
        "print(\"Treinamento concluído!\")\n",
        "\n",
        "# Avalia o modelo no conjunto de teste\n",
        "perda, acuracia = modelo_lstm.evaluate(X_teste, y_teste, verbose=0)\n",
        "print(f\"\\nAcurácia do modelo no conjunto de teste: {acuracia*100:.2f}%\")\n",
        "print(f\"Perda do modelo no conjunto de teste: {perda:.4f}\")\n",
        "\n",
        "# Fazer previsões no conjunto de teste\n",
        "y_pred_prob = modelo_lstm.predict(X_teste)\n",
        "y_pred_classes = (y_pred_prob > 0.5).astype(int) # Converter probabilidades para 0 ou 1\n",
        "\n",
        "print(\"\\n-- Relatório de Classificação --\")\n",
        "print(classification_report(y_teste, y_pred_classes, target_names=['negativo', 'positivo']))\n",
        "\n",
        "print(\"\\n-- Matriz de Confusão --\")\n",
        "cm = confusion_matrix(y_teste, y_pred_classes)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['negativo', 'positivo'], yticklabels=['negativo', 'positivo'])\n",
        "plt.xlabel('Previsto')\n",
        "plt.ylabel('Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EVoCbdcMTucL",
        "outputId": "3bc2c825-0430-47e2-9c42-def5c9da343a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando o treinamento do modelo LSTM...\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 194ms/step - accuracy: 0.4667 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6923\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5486 - loss: 0.6907 - val_accuracy: 0.5000 - val_loss: 0.6935\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2569 - loss: 0.6971 - val_accuracy: 0.5000 - val_loss: 0.6956\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8028 - loss: 0.6845 - val_accuracy: 0.5000 - val_loss: 0.6974\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8764 - loss: 0.6808 - val_accuracy: 0.5000 - val_loss: 0.7001\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8222 - loss: 0.6724 - val_accuracy: 0.0000e+00 - val_loss: 0.7044\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9181 - loss: 0.6601 - val_accuracy: 0.0000e+00 - val_loss: 0.7112\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9667 - loss: 0.6365 - val_accuracy: 0.0000e+00 - val_loss: 0.7227\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9181 - loss: 0.5946 - val_accuracy: 0.0000e+00 - val_loss: 0.7429\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7931 - loss: 0.5550 - val_accuracy: 0.0000e+00 - val_loss: 0.7852\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.4229 - val_accuracy: 0.0000e+00 - val_loss: 0.8868\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.3093 - val_accuracy: 0.0000e+00 - val_loss: 1.0934\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.1292 - val_accuracy: 0.0000e+00 - val_loss: 1.5218\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0739 - val_accuracy: 0.0000e+00 - val_loss: 2.1531\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0284 - val_accuracy: 0.0000e+00 - val_loss: 2.8293\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 0.0000e+00 - val_loss: 3.3905\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.0000e+00 - val_loss: 3.7940\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.0000e+00 - val_loss: 4.0863\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.0000e+00 - val_loss: 4.2942\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.0000e+00 - val_loss: 4.4487\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.0000e+00 - val_loss: 4.5693\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.0000e+00 - val_loss: 4.6715\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.0000e+00 - val_loss: 4.7596\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.0000e+00 - val_loss: 4.8309\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.0000e+00 - val_loss: 4.8953\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.0000e+00 - val_loss: 4.9516\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.0000e+00 - val_loss: 5.0091\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.0000e+00 - val_loss: 5.0625\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.0000e+00 - val_loss: 5.1175\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.0000e+00 - val_loss: 5.1670\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.0000e+00 - val_loss: 5.2129\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.0000e+00 - val_loss: 5.2590\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.0000e+00 - val_loss: 5.3086\n",
            "Epoch 34/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.0000e+00 - val_loss: 5.3591\n",
            "Epoch 35/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.0000e+00 - val_loss: 5.4176\n",
            "Epoch 36/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.0000e+00 - val_loss: 5.4680\n",
            "Epoch 37/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 8.2143e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.5155\n",
            "Epoch 38/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.0000e+00 - val_loss: 5.5612\n",
            "Epoch 39/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 8.0072e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.6001\n",
            "Epoch 40/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.0000e+00 - val_loss: 5.6401\n",
            "Epoch 41/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 9.2972e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.6789\n",
            "Epoch 42/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.0000e+00 - val_loss: 5.7190\n",
            "Epoch 43/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 6.7597e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.7555\n",
            "Epoch 44/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 6.7433e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.7894\n",
            "Epoch 45/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 7.1288e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.8222\n",
            "Epoch 46/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 4.8006e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.8531\n",
            "Epoch 47/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 5.4410e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.8825\n",
            "Epoch 48/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 7.5281e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.9130\n",
            "Epoch 49/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 6.0282e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.9423\n",
            "Epoch 50/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 7.3746e-04 - val_accuracy: 0.0000e+00 - val_loss: 5.9740\n",
            "Treinamento concluído!\n",
            "\n",
            "Acurácia do modelo no conjunto de teste: 100.00%\n",
            "Perda do modelo no conjunto de teste: 0.2321\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step\n",
            "\n",
            "-- Relatório de Classificação --\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo       1.00      1.00      1.00         2\n",
            "    positivo       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         3\n",
            "   macro avg       1.00      1.00      1.00         3\n",
            "weighted avg       1.00      1.00      1.00         3\n",
            "\n",
            "\n",
            "-- Matriz de Confusão --\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAHHCAYAAAAf2DoOAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAULNJREFUeJzt3X1cjff/B/DX6e50p6Mb3U0UJTdDhBSGicSQbW7SVpoYc5+brf1GMVubDTHGDOX+bm5nlpuIoSK5mTFiEVapCCVFXb8/PJyvaxWVc51z5PXc43rM+ZzP+Vzvjtl5e78/13VkgiAIICIiIlITHU0HQERERK8XJh9ERESkVkw+iIiISK2YfBAREZFaMfkgIiIitWLyQURERGrF5IOIiIjUiskHERERqRWTDyIiIlIrJh9EKhIREQGZTCbpOWQyGSIiIiQ9h7p99913aNCgAXR1deHm5ibJOSZPnoxatWohKCgIt2/fRtOmTXH69GlJzkVEL8bkg145MTExkMlkkMlkOHLkSJnnBUGAg4MDZDIZ3nnnnWqd4+uvv8b27dtfMtJXQ0lJCaKjo9GlSxdYWFhALpfD0dERwcHBSE5OlvTce/fuxdSpU9GhQwdER0fj66+/Vvk58vPzsXjxYsycORN//fUXrKysYGpqihYtWqj8XERUOUw+6JVlaGiIdevWlRk/dOgQbty4AblcXu21q5N8fPHFFygsLKz2OTWhsLAQ77zzDj766CMIgoDPP/8cixcvRmBgIBISEtCuXTvcuHFDsvMfOHAAOjo6WL58OQIDA9GrVy+Vn8PQ0BDnz5/HxIkTkZycjBs3biAxMRE6OvzfH5Gm6Gk6AKLq6tWrFzZv3owFCxZAT+9//ymvW7cO7u7uyMnJUUscBQUFMDExgZ6eniiOV8GUKVMQGxuLefPmYcKECaLnwsPDMW/ePEnPf+vWLRgZGcHAwECyc+jp6aF+/frKx/b29pKdi4gqh6k/vbL8/f2Rm5uLffv2KceKi4vxyy+/YMiQIeW+5vvvv4eXlxcsLS1hZGQEd3d3/PLLL6I5MpkMBQUFWLlypbK9M3ToUAD/29dx/vx5DBkyBObm5ujYsaPouaeGDh2qfP1/jxft2ygqKsLEiRNRp04d1KpVC3379q2wAnHz5k189NFHsLGxgVwuR7NmzbBixYoXvX24ceMGfvrpJ3Tv3r1M4gEAurq6mDx5MurWrascO3XqFHx9fWFmZgZTU1N069YNiYmJotc9bYsdPXoUoaGhqFOnDkxMTNC/f39kZ2cr58lkMkRHR6OgoED5vsTExODq1avKX//Xf9+7+/fvY8KECXB0dIRcLoe1tTW6d++OlJQU5Zz4+Hi8//77qFevHuRyORwcHDBx4sRyq1QHDhxAp06dYGJigtq1a6Nfv364cOHCC99LIqqaV+uvaUTPcHR0hKenJ9avXw9fX18AwO+//467d+9i8ODBWLBgQZnXzJ8/H3379kVAQACKi4uxYcMGDBgwALt27ULv3r0BAKtXr0ZISAjatWuHESNGAAAaNmwoWmfAgAFwcXHB119/DUEQyo3v448/hre3t2gsNjYWa9euhbW19XN/tpCQEKxZswZDhgyBl5cXDhw4oIzvWVlZWWjfvj1kMhnGjBmDOnXq4Pfff8ewYcNw7969cpOKp37//Xc8fvwYH3744XNjeeqvv/5Cp06dYGZmhqlTp0JfXx8//fQTunTpgkOHDsHDw0M0f+zYsTA3N0d4eDiuXr2KqKgojBkzBhs3bgTw5H1eunQpjh8/jmXLlgEAvLy8KhXLUyNHjsQvv/yCMWPGoGnTpsjNzcWRI0dw4cIFtG7dGgCwadMmFBYW4pNPPoGFhQWOHz+OH374ATdu3MDmzZuVa+3fvx++vr5o0KABIiIiUFhYiB9++AEdOnRASkoKHB0dqxQbET2HQPSKiY6OFgAIJ06cEBYuXCjUqlVLePDggSAIgjBgwACha9eugiAIQv369YXevXuLXvt03lPFxcXCm2++Kbz99tuicRMTEyEoKKjMucPDwwUAgr+/f4XPVSQ1NVVQKBRC9+7dhcePH1c47/Tp0wIA4ZNPPhGNDxkyRAAghIeHK8eGDRsm2NnZCTk5OaK5gwcPFhQKRZmf91kTJ04UAAinTp2qcM6z/Pz8BAMDA+HKlSvKsX///VeoVauW8NZbbynHnv7+eHt7C6WlpaLz6erqCnl5ecqxoKAgwcTERHSetLQ0AYAQHR1dJob//vwKhUIYPXr0c+MuKCgoMxYZGSnIZDLh2rVryjE3NzfB2tpayM3NVY6dOXNG0NHREQIDA597DiKqGrZd6JU2cOBAFBYWYteuXbh//z527dpVYcsFAIyMjJS/vnPnDu7evYtOnTqJyvSVMXLkyCrNLygoQP/+/WFubo7169dDV1e3wrm7d+8GAIwbN040/t8qhiAI2LJlC/r06QNBEJCTk6M8fHx8cPfu3ef+XPfu3QMA1KpV64Xxl5SUYO/evfDz80ODBg2U43Z2dhgyZAiOHDmiXO+pESNGiNpQnTp1QklJCa5du/bC81VW7dq1kZSUhH///bfCOcbGxspfFxQUICcnB15eXhAEAadOnQIAZGRk4PTp0xg6dCgsLCyU81u0aIHu3bsrf0+ISDXYdqFXWp06deDt7Y1169bhwYMHKCkpwfvvv1/h/F27dmHWrFk4ffo0ioqKlONVvT+Hk5NTleYPHz4cV65cwbFjx2BpafncudeuXYOOjk6ZVo+rq6vocXZ2NvLy8rB06VIsXbq03LVu3bpV4XnMzMwAPNk38SLZ2dl48OBBmRgAoEmTJigtLcX169fRrFkz5Xi9evVE88zNzQE8SfpUZfbs2QgKCoKDgwPc3d3Rq1cvBAYGihKk9PR0TJ8+HTt37ixz7rt37wKAMiGq6Ofbs2ePcmMxEb08Jh/0yhsyZAiGDx+OzMxM+Pr6onbt2uXO++OPP9C3b1+89dZb+PHHH2FnZwd9fX1ER0eXe8nu8zxbQXmR+fPnY/369VizZo1Kb6JVWloKAPjggw8QFBRU7pzn3cuicePGAIA///xTkpt7VVTdESrYI/NURYlgSUlJmbGBAweiU6dO2LZtG/bu3YvvvvsO3377LbZu3QpfX1+UlJSge/fuuH37Nj799FM0btwYJiYmuHnzJoYOHap8D4lIvZh80Cuvf//++Pjjj5GYmKjczFieLVu2wNDQEHv27BHdAyQ6OrrMXFXdqfSPP/7A5MmTMWHCBAQEBFTqNfXr10dpaSmuXLki+pv4xYsXRfOeXglTUlJSZmNrZfj6+kJXVxdr1qx54abTOnXqwNjYuEwMAPD3339DR0cHDg4OVY6hPE8rJHl5eaLxito1dnZ2+OSTT/DJJ5/g1q1baN26Nb766iv4+vrizz//xKVLl7By5UoEBgYqX/PsFVIAlJfiVvTzWVlZsepBpELc80GvPFNTUyxevBgRERHo06dPhfN0dXUhk8lEf4O+evVquTcTMzExKfPhV1UZGRkYOHAgOnbsiO+++67Sr3t65c5/r9aJiooSPdbV1cV7772HLVu24Ny5c2XWefay1vI4ODhg+PDh2Lt3L3744Ycyz5eWlmLOnDm4ceMGdHV10aNHD+zYsQNXr15VzsnKysK6devQsWNHZRvnZZmZmcHKygqHDx8Wjf/444+ixyUlJcq2yVPW1tawt7dXttSeVl+erbYIgoD58+eLXmdnZwc3NzesXLlS9Pt+7tw57N27V5KbnxG9zlj5oBqhorbDs3r37o25c+eiZ8+eGDJkCG7duoVFixbB2dkZZ8+eFc11d3fH/v37MXfuXNjb28PJyanMpaQvMm7cOGRnZ2Pq1KnYsGGD6LkWLVpU2BJxc3ODv78/fvzxR9y9exdeXl6Ii4vD5cuXy8z95ptvcPDgQXh4eGD48OFo2rQpbt++jZSUFOzfvx+3b99+boxz5szBlStXMG7cOGzduhXvvPMOzM3NkZ6ejs2bN+Pvv//G4MGDAQCzZs3Cvn370LFjR3zyySfQ09PDTz/9hKKiIsyePbtK782LhISE4JtvvkFISAjatGmDw4cP49KlS6I59+/fR926dfH++++jZcuWMDU1xf79+3HixAnMmTMHwJPWUsOGDTF58mTcvHkTZmZm2LJlS7n7Tr777jv4+vrC09MTw4YNU15qq1Aoatz36RBpnCYvtSGqjmcvtX2e8i61Xb58ueDi4iLI5XKhcePGQnR0dLmXyP7999/CW2+9JRgZGQkAlJfdPp2bnZ1d5nz/Xadz584CgHKPZy8XLU9hYaEwbtw4wdLSUjAxMRH69OkjXL9+vdzXZmVlCaNHjxYcHBwEfX19wdbWVujWrZuwdOnS557jqcePHwvLli0TOnXqJCgUCkFfX1+oX7++EBwcXOYy3JSUFMHHx0cwNTUVjI2Nha5duwrHjh0Tzano9+fgwYMCAOHgwYPKsfIutRWEJ5dEDxs2TFAoFEKtWrWEgQMHCrdu3RL9/EVFRcKUKVOEli1bCrVq1RJMTEyEli1bCj/++KNorfPnzwve3t6CqampYGVlJQwfPlw4c+ZMuZfz7t+/X+jQoYNgZGQkmJmZCX369BHOnz9fqfeRiCpPJggv2P1FREREpELc80FERERqxeSDiIiI1IrJBxEREakVkw8iIqIaKDIyEm3btkWtWrVgbW0NPz+/cu9l81+bN29G48aNYWhoiObNm5f5egFBEDB9+nTY2dnByMgI3t7eSE1NrVJsTD6IiIhqoEOHDmH06NFITEzEvn378OjRI/To0QMFBQUVvubYsWPw9/fHsGHDcOrUKfj5+cHPz090L6HZs2djwYIFWLJkCZKSkmBiYgIfHx88fPiw0rHxahciIqLXQHZ2NqytrXHo0CG89dZb5c4ZNGgQCgoKsGvXLuVY+/bt4ebmhiVLlkAQBNjb22PSpEmYPHkygCffkWRjY4OYmBjlfYFehJUPIiKiV0RRURHu3bsnOp79kszneXpH4Ge/ufm/EhISynxdg4+PDxISEgAAaWlpyMzMFM1RKBTw8PBQzqmMGnmHU6NWYzQdApFWunNioaZDINI6hmr4JFTV59Kn/awwY8YM0Vh4ePgL78JbWlqKCRMmoEOHDnjzzTcrnJeZmQkbGxvRmI2NDTIzM5XPPx2raE5l1Mjkg4iIqCYKCwtDaGioaOzZL8qsyOjRo3Hu3DkcOXJEqtCqhMkHERGR1GSq2eUgl8srlWw8a8yYMdi1axcOHz6MunXrPneura0tsrKyRGNZWVmwtbVVPv90zM7OTjTHzc2t0jFxzwcREZHUZDLVHFUgCALGjBmDbdu24cCBA3Bycnrhazw9PREXFyca27dvHzw9PQEATk5OsLW1Fc25d+8ekpKSlHMqg5UPIiIiqamo8lEVo0ePxrp167Bjxw7UqlVLuSdDoVDAyMgIABAYGIg33ngDkZGRAIDx48ejc+fOmDNnDnr37o0NGzYgOTkZS5cuffJjyGSYMGECZs2aBRcXFzg5OWHatGmwt7eHn59fpWNj8kFERFQDLV68GADQpUsX0Xh0dDSGDh0KAEhPT4eOzv8SIy8vL6xbtw5ffPEFPv/8c7i4uGD79u2iTapTp05FQUEBRowYgby8PHTs2BGxsbEwNDSsdGw18j4fvNqFqHy82oWoLLVc7dI29MWTKqHwxFyVrKNprHwQERFJTQNtF23Gd4OIiIjUipUPIiIiqVXxSpWajskHERGR1Nh2EeG7QURERGrFygcREZHU2HYRYfJBREQkNbZdRPhuEBERkVqx8kFERCQ1tl1EmHwQERFJjW0XESYfREREUmPlQ4SpGBEREakVKx9ERERSY9tFhMkHERGR1Jh8iPDdICIiIrVi5YOIiEhqOtxw+iwmH0RERFJj20WE7wYRERGpFSsfREREUuN9PkSYfBAREUmNbRcRvhtERESkVqx8EBERSY1tFxEmH0RERFJj20WEyQcREZHUWPkQYSpGREREasXKBxERkdTYdhFh8kFERCQ1tl1EmIoRERGRWrHyQUREJDW2XUSYfBAREUmNbRcRpmJERESkVqx8EBERSY1tFxEmH0RERFJj8iHCd4OIiIjUipUPIiIiqXHDqQgrH0RERFKT6ajmqKLDhw+jT58+sLe3h0wmw/bt2587f+jQoZDJZGWOZs2aKedERESUeb5x48ZViovJBxERkdRkMtUcVVRQUICWLVti0aJFlZo/f/58ZGRkKI/r16/DwsICAwYMEM1r1qyZaN6RI0eqFBfbLkRERDWUr68vfH19Kz1foVBAoVAoH2/fvh137txBcHCwaJ6enh5sbW2rHRcrH0RERFJTUdulqKgI9+7dEx1FRUWShb18+XJ4e3ujfv36ovHU1FTY29ujQYMGCAgIQHp6epXWZfJBREQkNRW1XSIjI5XViadHZGSkJCH/+++/+P333xESEiIa9/DwQExMDGJjY7F48WKkpaWhU6dOuH//fqXXZtuFiIjoFREWFobQ0FDRmFwul+RcK1euRO3ateHn5ycaf7aN06JFC3h4eKB+/frYtGkThg0bVqm1mXwQERFJTKaiS23lcrlkycazBEHAihUr8OGHH8LAwOC5c2vXro1GjRrh8uXLlV6fbRciIiKJlXf5anUOdTl06BAuX75cqUpGfn4+rly5Ajs7u0qvz+SDiIiohsrPz8fp06dx+vRpAEBaWhpOnz6t3CAaFhaGwMDAMq9bvnw5PDw88Oabb5Z5bvLkyTh06BCuXr2KY8eOoX///tDV1YW/v3+l42LbhYiISGoausFpcnIyunbtqnz8dL9IUFAQYmJikJGRUeZKlbt372LLli2YP39+uWveuHED/v7+yM3NRZ06ddCxY0ckJiaiTp06lY5LJgiCUI2fR6sZtRqj6RCItNKdEws1HQKR1jFUw1/DTQfGqGSd/E1DVbKOprHtQkRERGrFtgsREZHE1LlZ9FXA5IOIiEhiTD7EmHwQERFJjMmHGPd8EBERkVqx8kFERCQ1Fj5EmHwQERFJjG0XMbZdiIiISK1Y+SAiIpIYKx9iTD6IiIgkxuRDjG0XIiIiUitWPoiIiCTGyoeY1iUfT7/njr9RRERUY/AjTURr2i6rVq1C8+bNYWRkBCMjI7Ro0QKrV6/WdFhERESkYlpR+Zg7dy6mTZuGMWPGoEOHDgCAI0eOYOTIkcjJycHEiRM1HCEREVH1sZovphXJxw8//IDFixcjMDBQOda3b180a9YMERERTD6IiOiVxuRDTCuSj4yMDHh5eZUZ9/LyQkZGhgYiIiIiUh0mH2JasefD2dkZmzZtKjO+ceNGuLi4aCAiIiIikopWVD5mzJiBQYMG4fDhw8o9H0ePHkVcXFy5SQkREdErhYUPEa1IPt577z0kJSVh3rx52L59OwCgSZMmOH78OFq1aqXZ4IiIiF4S2y5iWpF8AIC7uzvWrFmj6TCIiIhIYlqx58Pb2xsxMTG4d++epkMhIiJSOZlMppKjptCK5KNZs2YICwuDra0tBgwYgB07duDRo0eaDouIiEglmHyIaUXyMX/+fNy8eRPbt2+HiYkJAgMDYWNjgxEjRuDQoUOaDo+IiIhUSCuSDwDQ0dFBjx49EBMTg6ysLPz00084fvw43n77bU2HRkRE9FJY+RDTmg2nT2VmZmLDhg1Ys2YNzp49i3bt2mk6JCIiopdTc/IGldCKyse9e/cQHR2N7t27w8HBAYsXL0bfvn2RmpqKxMRETYdHREREKqQVlQ8bGxuYm5tj0KBBiIyMRJs2bTQdEhERkcrUpJaJKmhF8rFz505069YNOjpaUYghIiJSKSYfYlqRfHTv3l3TIRAREUmGyYeYxpKP1q1bIy4uDubm5mjVqtVzf2NSUlLUGBkRERFJSWPJR79+/SCXy5W/ZlZIREQ1Fj/iRDSWfISHhyt/HRERoakwiIiIJMe/YItpxQ7PBg0aIDc3t8x4Xl4eGjRooIGIiIiISCpaseH06tWrKCkpKTNeVFSEGzduaCAiehmTP+oBv7dbopGjDQqLHiHpzD/4v/k7kHrtlqZDI9K4DevWYmX0cuTkZKORa2N89vk0NG/RQtNhkcRY+RDTaOVj586d2LlzJwBgz549ysc7d+7Etm3b8OWXX8LJyUmTIVI1dGrtjCUbD6Nz4Pd4Z9RC6OnpYtfiMTA2NNB0aEQaFfv7bnw/OxIffzIaGzZvg6trY4z6eFi5lV+qWTR1e/XDhw+jT58+sLe3h0wmw/bt2587Pz4+vtzzZmZmiuYtWrQIjo6OMDQ0hIeHB44fP16luDRa+fDz8wPw5DclKChI9Jy+vj4cHR0xZ84cDURGL6PfmB9Fj0eEr8H1A9+gVVMHHE25oqGoiDRv9cpovPv+QPj1fw8A8EX4DBw+HI/tW7dg2PARGo6OaqKCggK0bNkSH330Ed59991Kv+7ixYswMzNTPra2tlb+euPGjQgNDcWSJUvg4eGBqKgo+Pj44OLFi6J5z6PR5KO0tBQA4OTkhBMnTsDKykqT4ZBEzEwNAQB37j7QcCREmvOouBgXzv+FYcM/Vo7p6OigfXsvnD1zSoORkTpoqu3i6+sLX1/fKr/O2toatWvXLve5uXPnYvjw4QgODgYALFmyBL/99htWrFiBzz77rFLra8WG07S0NCYeNZRMJsN3k9/HsVNXcP5KhqbDIdKYO3l3UFJSAktLS9G4paUlcnJyNBQVqY1MRYeauLm5wc7ODt27d8fRo0eV48XFxTh58iS8vb2VYzo6OvD29kZCQkKl19eKDafAk9LQoUOHkJ6ejuLiYtFz48aNq/B1RUVFKCoqEo0JpSWQ6ehKEidVTVTYQDRztkO34HmaDoWI6JVX3meeXC5X3jfrZdnZ2WHJkiVo06YNioqKsGzZMnTp0gVJSUlo3bo1cnJyUFJSAhsbG9HrbGxs8Pfff1f6PFqRfJw6dQq9evXCgwcPUFBQAAsLC+Tk5MDY2BjW1tbPTT4iIyMxY8YM0ZiuTVvo27WTOmx6gXmfDkCvTm/Ce1gUbt7K03Q4RBplXtscurq6ZTaX5ubmsvL7GlBV26W8z7zw8HCV3S/L1dUVrq6uysdeXl64cuUK5s2bh9WrV6vkHICWtF0mTpyIPn364M6dOzAyMkJiYiKuXbsGd3d3fP/99899bVhYGO7evSs69Gzc1RQ5VWTepwPQ9+2W6PnxAlz7lzv5ifQNDNCkaTMkJf6vNF1aWoqkpAS0aNlKg5GROqjqapfyPvPCwsIkjb1du3a4fPkyAMDKygq6urrIysoSzcnKyoKtrW2l19SK5OP06dOYNGkSdHR0oKuri6KiIjg4OGD27Nn4/PPPn/tauVwOMzMz0cGWi2ZFhQ3E4N5tEfR5DPILHsLGshZsLGvBUK6v6dCINOrDoGBs/WUTdm7fhn+uXMGsmREoLCyEX//KX4VAryaZTDVHeZ95qmq5VOT06dOws7MDABgYGMDd3R1xcXHK50tLSxEXFwdPT89Kr6kVbRd9fX3o6DzJg6ytrZGeno4mTZpAoVDg+vXrGo6OqurjgW8BAPYtmyAaHz59Ndb8mqSBiIi0Q0/fXrhz+zZ+XLgAOTnZcG3cBD/+tAyWbLuQRPLz85VVC+DJBR6nT5+GhYUF6tWrh7CwMNy8eROrVq0CAERFRcHJyQnNmjXDw4cPsWzZMhw4cAB79+5VrhEaGoqgoCC0adMG7dq1Q1RUFAoKCpRXv1SGViQfrVq1wokTJ+Di4oLOnTtj+vTpyMnJwerVq/Hmm29qOjyqIqNWYzQdApHW8g/4AP4BH2g6DFIzTV1qm5ycjK5duyofh4aGAgCCgoIQExODjIwMpKenK58vLi7GpEmTcPPmTRgbG6NFixbYv3+/aI1BgwYhOzsb06dPR2ZmJtzc3BAbG1tmE+rzyARBEFTw872U5ORk3L9/H127dsWtW7cQGBiIY8eOwcXFBStWrEDLli2rtB4//IjKd+fEQk2HQKR1DNXw1/BGU2NVss6l2T1Vso6maUXlo02bNspfW1tbIzZWNb9JREREpH20IvkgIiKqyfjFcmJakXy0atWq3N8YmUwGQ0NDODs7Y+jQoaKeExER0auCuYeYVlxq27NnT/zzzz8wMTFB165d0bVrV5iamuLKlSto27YtMjIy4O3tjR07dmg6VCIiInpJWlH5yMnJwaRJkzBt2jTR+KxZs3Dt2jXs3bsX4eHh+PLLL9GvXz8NRUlERFQ9OjosfTxLKyofmzZtgr+/f5nxwYMHY9OmTQAAf39/XLx4Ud2hERERvTRV3WSsptCK5MPQ0BDHjh0rM37s2DEYGj75OvbS0lLlr4mIiOjVpRVtl7Fjx2LkyJE4efIk2rZtCwA4ceIEli1bpry9+p49e+Dm5qbBKImIiKqHV7uIacVNxgBg7dq1WLhwobK14urqirFjx2LIkCEAgMLCQuXVLy/Cm4wRlY83GSMqSx03GWs+bZ9K1vnzy+4qWUfTtKLyAQABAQEICAio8HkjIyM1RkNERKQ6rHyIacWeDwDIy8tTtllu374NAEhJScHNmzc1HBkRERGpklZUPs6ePQtvb28oFApcvXoVISEhsLCwwNatW5Genq78tj0iIqJXESsfYlpR+QgNDcXQoUORmpoq2tPRq1cvHD58WIORERERvTxeaiumFcnHiRMn8PHHH5cZf+ONN5CZmamBiIiIiEgqWtF2kcvluHfvXpnxS5cuoU6dOhqIiIiISHXYdhHTispH3759MXPmTDx69AjAk9+k9PR0fPrpp3jvvfc0HB0REdHLYdtFTCuSjzlz5iA/Px/W1tYoLCxE586d4ezsDFNTU3z11VeaDo+IiIhUSCvaLgqFAvv27cPRo0dx5swZ5Ofno3Xr1vD29tZ0aERERC+NbRcxrUg+ACAuLg5xcXG4desWSktL8ffff2PdunUAgBUrVmg4OiIioupj7iGmFcnHjBkzMHPmTLRp0wZ2dnbMEImIiGowrUg+lixZgpiYGHz44YeaDoWIiEjl+JdqMa1IPoqLi+Hl5aXpMIiIiCTB3ENMK652CQkJUe7vICIiqmlkMplKjppCKyofDx8+xNKlS7F//360aNEC+vr6oufnzp2rociIiIhI1bQi+Th79izc3NwAAOfOnRM9V5MyPSIiej3xo0xMK5KPgwcPajoEIiIiyfAv0mJaseeDiIiIXh9aUfkgIiKqyVj4EGPyQUREJDG2XcTYdiEiIiK1YuWDiIhIYix8iDH5ICIikhjbLmJsuxAREZFasfJBREQkMVY+xJh8EBERSYy5hxjbLkRERBLT1BfLHT58GH369IG9vT1kMhm2b9/+3Plbt25F9+7dUadOHZiZmcHT0xN79uwRzYmIiCgTV+PGjasUF5MPIiKiGqqgoAAtW7bEokWLKjX/8OHD6N69O3bv3o2TJ0+ia9eu6NOnD06dOiWa16xZM2RkZCiPI0eOVCkutl2IiIgkpqm2i6+vL3x9fSs9PyoqSvT466+/xo4dO/Drr7+iVatWynE9PT3Y2tpWOy5WPoiIiCSmqbbLyyotLcX9+/dhYWEhGk9NTYW9vT0aNGiAgIAApKenV2ldVj6IiIheEUVFRSgqKhKNyeVyyOVySc73/fffIz8/HwMHDlSOeXh4ICYmBq6ursjIyMCMGTPQqVMnnDt3DrVq1arUuqx8EBERSUwmU80RGRkJhUIhOiIjIyWJed26dZgxYwY2bdoEa2tr5bivry8GDBiAFi1awMfHB7t370ZeXh42bdpU6bVZ+SAiIpKYjopaJmFhYQgNDRWNSVH12LBhA0JCQrB582Z4e3s/d27t2rXRqFEjXL58udLrs/JBRET0ipDL5TAzMxMdqk4+1q9fj+DgYKxfvx69e/d+4fz8/HxcuXIFdnZ2lT4HKx9EREQS09TVLvn5+aKKRFpaGk6fPg0LCwvUq1cPYWFhuHnzJlatWgXgSaslKCgI8+fPh4eHBzIzMwEARkZGUCgUAIDJkyejT58+qF+/Pv7991+Eh4dDV1cX/v7+lY6LlQ8iIiKJaepql+TkZLRq1Up5mWxoaChatWqF6dOnAwAyMjJEV6osXboUjx8/xujRo2FnZ6c8xo8fr5xz48YN+Pv7w9XVFQMHDoSlpSUSExNRp06dyr8fgiAIVf5ptJxRqzGaDoFIK905sVDTIRBpHUM19AB8FyepZJ3fR3moZB1NY+WDiIiI1Ip7PoiIiCTGb7UVY/JBREQkMeYeYmy7EBERkVqx8kFERCQxGVj6eBaTDyIiIonpMPcQYduFiIiI1IqVDyIiIonxahcxJh9EREQSY+4hxrYLERERqRUrH0RERBLTYelDhMkHERGRxJh7iDH5ICIikhg3nIpxzwcRERGpFSsfREREEmPhQ4zJBxERkcS44VSMbRciIiJSK1Y+iIiIJMa6hxiTDyIiIonxahcxtl2IiIhIrVj5ICIikpgOCx8iTD6IiIgkxraLGNsuREREpFasfBAREUmMhQ8xJh9EREQSY9tFjMkHERGRxLjhVIx7PoiIiEitWPkgIiKSGNsuYkw+iIiIJMbUQ6zSyce7775b6UW3bt1arWCIiIio5qt08qFQKKSMg4iIqMbSYdtFpNLJR3R0tJRxEBER1VjMPcR4tQsRERGpVbU3nP7yyy/YtGkT0tPTUVxcLHouJSXlpQMjIiKqKXi1i1i1Kh8LFixAcHAwbGxscOrUKbRr1w6Wlpb4559/4Ovrq+oYiYiIXmkymWqOmqJaycePP/6IpUuX4ocffoCBgQGmTp2Kffv2Ydy4cbh7966qYyQiIqIapFrJR3p6Ory8vAAARkZGuH//PgDgww8/xPr161UXHRERUQ2gI5Op5Kiqw4cPo0+fPrC3t4dMJsP27dtf+Jr4+Hi0bt0acrkczs7OiImJKTNn0aJFcHR0hKGhITw8PHD8+PEqxVWt5MPW1ha3b98GANSrVw+JiYkAgLS0NAiCUJ0liYiIaixNtV0KCgrQsmVLLFq0qFLz09LS0Lt3b3Tt2hWnT5/GhAkTEBISgj179ijnbNy4EaGhoQgPD0dKSgpatmwJHx8f3Lp1q9JxVWvD6dtvv42dO3eiVatWCA4OxsSJE/HLL78gOTm5SjcjIyIieh1oasOpr69vlfZiLlmyBE5OTpgzZw4AoEmTJjhy5AjmzZsHHx8fAMDcuXMxfPhwBAcHK1/z22+/YcWKFfjss88qdZ5qJR9Lly5FaWkpAGD06NGwtLTEsWPH0LdvX3z88cfVWZKIiIheoKioCEVFRaIxuVwOuVyukvUTEhLg7e0tGvPx8cGECRMAAMXFxTh58iTCwsKUz+vo6MDb2xsJCQmVPk+1kg8dHR3o6PyvYzN48GAMHjy4OktJ4s6JhZoOgUgrTfr1gqZDINI6i/o3kfwcqrqpVmRkJGbMmCEaCw8PR0REhErWz8zMhI2NjWjMxsYG9+7dQ2FhIe7cuYOSkpJy5/z999+VPk+1348//vgDH3zwATw9PXHz5k0AwOrVq3HkyJHqLklERFQjyWQylRxhYWG4e/eu6Hi2CvGqqFbysWXLFvj4+MDIyAinTp1SloDu3r2Lr7/+WqUBEhER0RNyuRxmZmaiQ1UtF+DJBSVZWVmisaysLJiZmcHIyAhWVlbQ1dUtd46trW2lz1Ot5GPWrFlYsmQJfv75Z+jr6yvHO3TowLubEhER/YeOTDWH1Dw9PREXFyca27dvHzw9PQEABgYGcHd3F80pLS1FXFycck5lVGvPx8WLF/HWW2+VGVcoFMjLy6vOkkRERDWWOhKH8uTn5+Py5cvKx2lpaTh9+jQsLCxQr149hIWF4ebNm1i1ahUAYOTIkVi4cCGmTp2Kjz76CAcOHMCmTZvw22+/KdcIDQ1FUFAQ2rRpg3bt2iEqKgoFBQXKq18qo1rJh62tLS5fvgxHR0fR+JEjR9CgQYPqLElEREQqlpycjK5duyofh4aGAgCCgoIQExODjIwMpKenK593cnLCb7/9hokTJ2L+/PmoW7culi1bprzMFgAGDRqE7OxsTJ8+HZmZmXBzc0NsbGyZTajPU63kY/jw4Rg/fjxWrFgBmUyGf//9FwkJCZg0aRKmT59enSWJiIhqLE3d56NLly7PvflneXcv7dKlC06dOvXcdceMGYMxY8ZUO65qJR+fffYZSktL0a1bNzx48ABvvfUW5HI5pkyZgpCQkGoHQ0REVBNpqu2iraq14VQmk+H//u//cPv2bZw7dw6JiYnIzs6GQqGAk5OTqmMkIiKiGqRKyUdRURHCwsLQpk0bdOjQAbt370bTpk3x119/wdXVFfPnz8fEiROlipWIiOiVpKnvdtFWVWq7TJ8+HT/99BO8vb1x7NgxDBgwAMHBwUhMTMScOXMwYMAA6OrqShUrERHRK6k630hbk1Up+di8eTNWrVqFvn374ty5c2jRogUeP36MM2fOaGwzDRERkbZT1e3Va4oqvR83btyAu7s7AODNN9+EXC7HxIkTmXgQERFRpVWp8lFSUgIDA4P/vVhPD6ampioPioiIqCbh39HFqpR8CIKAoUOHKu8j//DhQ4wcORImJiaieVu3blVdhERERK847vkQq1LyERQUJHr8wQcfqDQYIiIiqvmqlHxER0dLFQcREVGNxcKHWLXucEpERESVxzucivHqHyIiIlIrVj6IiIgkxg2nYkw+iIiIJMbcQ4xtFyIiIlIrVj6IiIgkxg2nYkw+iIiIJCYDs49nMfkgIiKSGCsfYtzzQURERGrFygcREZHEWPkQY/JBREQkMRmvtRVh24WIiIjUipUPIiIiibHtIsbkg4iISGLsuoix7UJERERqxcoHERGRxPjFcmJMPoiIiCTGPR9ibLsQERGRWrHyQUREJDF2XcSYfBAREUlMh18sJ8Lkg4iISGKsfIhxzwcRERGpFSsfREREEuPVLmJMPoiIiCTG+3yIse1CREREasXkg4iISGIymWqO6li0aBEcHR1haGgIDw8PHD9+vMK5Xbp0gUwmK3P07t1bOWfo0KFlnu/Zs2eVYmLbhYiISGKaarts3LgRoaGhWLJkCTw8PBAVFQUfHx9cvHgR1tbWZeZv3boVxcXFyse5ublo2bIlBgwYIJrXs2dPREdHKx/L5fIqxcXKBxERUQ01d+5cDB8+HMHBwWjatCmWLFkCY2NjrFixotz5FhYWsLW1VR779u2DsbFxmeRDLpeL5pmbm1cpLiYfREREElNV26WoqAj37t0THUVFReWes7i4GCdPnoS3t7dyTEdHB97e3khISKhU3MuXL8fgwYNhYmIiGo+Pj4e1tTVcXV0xatQo5ObmVun9YPJBREQkMR0VHZGRkVAoFKIjMjKy3HPm5OSgpKQENjY2onEbGxtkZma+MObjx4/j3LlzCAkJEY337NkTq1atQlxcHL799lscOnQIvr6+KCkpqezbwT0fREREr4qwsDCEhoaKxqq636Kyli9fjubNm6Ndu3ai8cGDByt/3bx5c7Ro0QINGzZEfHw8unXrVqm1WfkgIiKSWHlXkFTnkMvlMDMzEx0VJR9WVlbQ1dVFVlaWaDwrKwu2trbPjbegoAAbNmzAsGHDXvizNWjQAFZWVrh8+XKl3w8mH0RERBKTqeioCgMDA7i7uyMuLk45Vlpairi4OHh6ej73tZs3b0ZRURE++OCDF57nxo0byM3NhZ2dXaVjY/JBREQkMR2ZTCVHVYWGhuLnn3/GypUrceHCBYwaNQoFBQUIDg4GAAQGBiIsLKzM65YvXw4/Pz9YWlqKxvPz8zFlyhQkJibi6tWriIuLQ79+/eDs7AwfH59Kx8U9H0RERDXUoEGDkJ2djenTpyMzMxNubm6IjY1VbkJNT0+Hjo64DnHx4kUcOXIEe/fuLbOerq4uzp49i5UrVyIvLw/29vbo0aMHvvzyyyrtPZEJgiC83I+mfR4+1nQERNpp0q8XNB0CkdZZ1L+J5OdYe/KGStYJcK+rknU0jZUPIiIiifF75cS454OIiIjUipUPIiIiiclY+hBh8kFERCQxthnE+H4QERGRWrHyQUREJDG2XcSYfBAREUmMqYcY2y5ERESkVqx8EBERSYxtFzEmH0RERBJjm0GMyQcREZHEWPkQYzJGREREasXKBxERkcRY9xBj8kFERCQxdl3E2HYhIiIitWLlg4iISGI6bLyIaE3ykZeXh+XLl+PChQsAgGbNmuGjjz6CQqHQcGREREQvh20XMa1ouyQnJ6Nhw4aYN28ebt++jdu3b2Pu3Llo2LAhUlJSNB0eERERqZBWVD4mTpyIvn374ueff4ae3pOQHj9+jJCQEEyYMAGHDx/WcIRERETVJ2PbRUQrko/k5GRR4gEAenp6mDp1Ktq0aaPByIiIiF4e2y5iWtF2MTMzQ3p6epnx69evo1atWhqIiIiIiKSiFcnHoEGDMGzYMGzcuBHXr1/H9evXsWHDBoSEhMDf31/T4REREb0UHchUctQUWtF2+f777yGTyRAYGIjHjx8DAPT19TFq1Ch88803Go6OiIjo5bDtIqYVyYeBgQHmz5+PyMhIXLlyBQDQsGFDGBsbazgyIiKil8fkQ0wr2i5r1qzBgwcPYGxsjObNm6N58+ZMPIiIiGoorUg+Jk6cCGtrawwZMgS7d+9GSUmJpkMiIiJSGZmK/qkptCL5yMjIwIYNGyCTyTBw4EDY2dlh9OjROHbsmKZDIyIiemk6MtUcNYVWJB96enp45513sHbtWty6dQvz5s3D1atX0bVrVzRs2FDT4REREZEKacWG02cZGxvDx8cHd+7cwbVr15Tf9UJERPSqqkktE1XQisoHADx48ABr165Fr1698MYbbyAqKgr9+/fHX3/9penQiIiIXopMppqjptCKysfgwYOxa9cuGBsbY+DAgZg2bRo8PT01HRYRERFJQCuSD11dXWzatAk+Pj7Q1dXVdDhEREQqxbaLmFYkH2vXrtV0CERERJKpSVeqqILGko8FCxZgxIgRMDQ0xIIFC547d9y4cWqKioiIiKQmEwRB0MSJnZyckJycDEtLSzg5OVU4TyaT4Z9//qnS2g8fv2x0pAob1q3FyujlyMnJRiPXxvjs82lo3qKFpsN6rU36lVePaZKzpRG8XSzhUNsQtY308VPidZzNyNd0WK+9Rf2bSH6OPy7dUck6nRqZq2QdTdPY1S5paWmwtLRU/rqio6qJB2mH2N934/vZkfj4k9HYsHkbXF0bY9THw5Cbm6vp0Ig0xkBPBzfuFmHTmSxNh0JqpsmrXRYtWgRHR0cYGhrCw8MDx48fr3BuTEwMZDKZ6DA0NBTNEQQB06dPh52dHYyMjODt7Y3U1NQqxaQVl9rOnDkTDx48KDNeWFiImTNnaiAielmrV0bj3fcHwq//e2jo7IwvwmfA0NAQ27du0XRoRBpzPqsAuy5k40zGfU2HQmomU9FRVRs3bkRoaCjCw8ORkpKCli1bwsfHB7du3arwNWZmZsjIyFAe165dEz0/e/ZsLFiwAEuWLEFSUhJMTEzg4+ODhw8fVjourUg+ZsyYgfz8sqXHBw8eYMaMGRqIiF7Go+JiXDj/F9p7einHdHR00L69F86eOaXByIiIXi9z587F8OHDERwcjKZNm2LJkiUwNjbGihUrKnyNTCaDra2t8rCxsVE+JwgCoqKi8MUXX6Bfv35o0aIFVq1ahX///Rfbt2+vdFxakXwIggBZOfWkM2fOwMLC4rmvLSoqwr1790RHUVGRVKFSJdzJu4OSkhJlW+0pS0tL5OTkaCgqIiLN0ZHJVHJU5TOvuLgYJ0+ehLe39//i0NGBt7c3EhISKow1Pz8f9evXh4ODA/r16ye62WdaWhoyMzNFayoUCnh4eDx3zTLvR6VnSsDc3BwWFhaQyWRo1KgRLCwslIdCoUD37t0xcODA564RGRkJhUIhOr77NlJNPwEREdGLqartUt5nXmRk+Z95OTk5KCkpEVUuAMDGxgaZmZnlvsbV1RUrVqzAjh07sGbNGpSWlsLLyws3btwAAOXrqrJmeTR6n4+oqCgIgoCPPvoIM2bMgEKhUD5nYGAAR0fHF97pNCwsDKGhoaIxQVcuSbxUOea1zaGrq1tmc2lubi6srKw0FBUR0auvvM88uVx1n3menp6iz10vLy80adIEP/30E7788kuVnUejyUdQUBCAJ5fdenl5QV9fv8pryOXyMm88L7XVLH0DAzRp2gxJiQl4u9uT0lxpaSmSkhIw2P8DDUdHRKQBKrrJWHmfeRWxsrKCrq4usrLEV1dlZWXB1ta2Umvo6+ujVatWuHz5MgAoX5eVlQU7OzvRmm5ubpVaE9Bg2+XevXvKX7dq1QqFhYVl+lhPD3r1fBgUjK2/bMLO7dvwz5UrmDUzAoWFhfDr/66mQyPSGLmuDHUVctRVPPnwsDQ2QF2FHOZGWnGzaZKQTEX/VIWBgQHc3d0RFxenHCstLUVcXFylvz+tpKQEf/75pzLRcHJygq2trWjNe/fuISkpqUrfyaax/+LNzc2RkZEBa2tr1K5du9wNp083opaUlGggQnoZPX174c7t2/hx4QLk5GTDtXET/PjTMliy7UKvsXrmRpjQqb7y8fstnvTNE6/lYXVKhqbCohosNDQUQUFBaNOmDdq1a4eoqCgUFBQgODgYABAYGIg33nhDuW9k5syZaN++PZydnZGXl4fvvvsO165dQ0hICIAnV8JMmDABs2bNgouLC5ycnDBt2jTY29vDz8+v0nFpLPk4cOCA8kqWgwcPaioMkpB/wAfwD2Cbheip1JwHGL2Nd5l9HVX3BmEva9CgQcjOzsb06dORmZkJNzc3xMbGKjeMpqenQ0fnf02QO3fuYPjw4cjMzIS5uTnc3d1x7NgxNG3aVDln6tSpKCgowIgRI5CXl4eOHTsiNja2zM3Inkdjt1eXEvd8EJWPt1cnKksdt1c/8c9dlazTtoHixZNeAVpxn4/Y2FgcOXJE+XjRokVwc3PDkCFDcOeOau6HT0RERNpBK5KPKVOmKDeW/vnnnwgNDUWvXr2QlpZW5pIiIiKiV46m7q+upbRii3VaWpqyn7Rlyxb06dMHX3/9NVJSUtCrVy8NR0dERPRyqnqlSk2nFZUPAwMD5RfL7d+/Hz169AAAWFhY8FJbIiJ65WnyW221kVZUPjp27IjQ0FB06NABx48fx8aNGwEAly5dQt26dTUcHREREamSVlQ+Fi5cCD09Pfzyyy9YvHgx3njjDQDA77//jp49e2o4OiIiopfDLR9iWlH5qFevHnbt2lVmfN68eRqIhoiISMVqUuagAlqRfABPbuG6fft2XLjw5D4EzZo1Q9++faGrq6vhyIiIiEiVtCL5uHz5Mnr16oWbN2/C1dUVwJOvDXZwcMBvv/2Ghg0bajhCIiKi6uPVLmJasedj3LhxaNiwIa5fv46UlBSkpKQgPT0dTk5OGDdunKbDIyIieim82kVMKyofhw4dQmJiovK7XgDA0tIS33zzDTp06KDByIiIiEjVtCL5kMvluH//fpnx/Px8GBgYaCAiIiIi1alBRQuV0Iq2yzvvvIMRI0YgKSkJgiBAEAQkJiZi5MiR6Nu3r6bDIyIiejm81lZEK5KPBQsWoGHDhvD09IShoSEMDQ3h5eUFZ2dnzJ8/X9PhERERkQppRduldu3a2LFjBy5fvozz588DAJo2bQpnZ2cNR0ZERPTyeLWLmFYkHwCwfPlyzJs3D6mpqQAAFxcXTJgwASEhIRqOjIiI6OXUpCtVVEErko/p06dj7ty5GDt2LDw9PQEACQkJmDhxItLT0zFz5kwNR0hERFR9zD3EZIIgCJoOok6dOliwYAH8/f1F4+vXr8fYsWORk5NTpfUePlZldEQ1x6RfL2g6BCKts6h/E8nPce5GvkrWebOuqUrW0TStqHw8evQIbdq0KTPu7u6Ox4+ZSRAR0SuOpQ8Rrbja5cMPP8TixYvLjC9duhQBAQEaiIiIiEh1ZCr6p6bQisoH8GTD6d69e9G+fXsAQFJSEtLT0xEYGIjQ0FDlvLlz52oqRCIiIlIBrUg+zp07h9atWwMArly5AgCwsrKClZUVzp07p5wn43ZhIiJ6BfHjS0wrko+DBw9qOgQiIiLJMPcQ04o9H0RERPT60IrKBxERUY3G0ocIkw8iIiKJ1aQrVVSBbRciIiJSK1Y+iIiIJMarXcSYfBAREUmMuYcYkw8iIiKpMfsQ4Z4PIiIiUitWPoiIiCTGq13EmHwQERFJjBtOxdh2ISIiIrVi5YOIiEhiLHyIsfJBREQkNZmKjmpYtGgRHB0dYWhoCA8PDxw/frzCuT///DM6deoEc3NzmJubw9vbu8z8oUOHQiaTiY6ePXtWKSYmH0RERDXUxo0bERoaivDwcKSkpKBly5bw8fHBrVu3yp0fHx8Pf39/HDx4EAkJCXBwcECPHj1w8+ZN0byePXsiIyNDeaxfv75KcckEQRCq/VNpqYePNR0BkXaa9OsFTYdApHUW9W8i+Tn+yX6oknUa1DGs0nwPDw+0bdsWCxcuBACUlpbCwcEBY8eOxWefffbC15eUlMDc3BwLFy5EYGAggCeVj7y8PGzfvr3K8T/FygcREZHEZDLVHFVRXFyMkydPwtvbWzmmo6MDb29vJCQkVGqNBw8e4NGjR7CwsBCNx8fHw9raGq6urhg1ahRyc3OrFBs3nBIREb0iioqKUFRUJBqTy+WQy+Vl5ubk5KCkpAQ2NjaicRsbG/z999+VOt+nn34Ke3t7UQLTs2dPvPvuu3BycsKVK1fw+eefw9fXFwkJCdDV1a3Uuqx8EBERSUxV+00jIyOhUChER2RkpCQxf/PNN9iwYQO2bdsGQ8P/tXsGDx6Mvn37onnz5vDz88OuXbtw4sQJxMfHV3ptVj6IiIikpqJrbcPCwhAaGioaK6/qAQBWVlbQ1dVFVlaWaDwrKwu2trbPPc/333+Pb775Bvv370eLFi2eO7dBgwawsrLC5cuX0a1bt0r8FKx8EBERSU6mon/kcjnMzMxER0XJh4GBAdzd3REXF6ccKy0tRVxcHDw9PSuMdfbs2fjyyy8RGxuLNm3avPBnu3HjBnJzc2FnZ1fp94PJBxERUQ0VGhqKn3/+GStXrsSFCxcwatQoFBQUIDg4GAAQGBiIsLAw5fxvv/0W06ZNw4oVK+Do6IjMzExkZmYiPz8fAJCfn48pU6YgMTERV69eRVxcHPr16wdnZ2f4+PhUOi62XYiIiCSmqe92GTRoELKzszF9+nRkZmbCzc0NsbGxyk2o6enp0NH5Xx1i8eLFKC4uxvvvvy9aJzw8HBEREdDV1cXZs2excuVK5OXlwd7eHj169MCXX35ZYQWmPLzPB9FrhPf5ICpLHff5uH676MWTKsHBovIf8NqMbRciIiJSK7ZdiIiIJKaptou2YvJBREQkOWYfz2LbhYiIiNSKlQ8iIiKJse0ixuSDiIhIYsw9xNh2ISIiIrVi5YOIiEhibLuIMfkgIiKSmIyNFxEmH0RERFJj7iHCPR9ERESkVqx8EBERSYyFDzEmH0RERBLjhlMxtl2IiIhIrVj5ICIikhivdhFj8kFERCQ15h4ibLsQERGRWrHyQUREJDEWPsSYfBAREUmMV7uIse1CREREasXKBxERkcR4tYsYkw8iIiKJse0ixrYLERERqRWTDyIiIlIrtl2IiIgkxraLGJMPIiIiiXHDqRjbLkRERKRWrHwQERFJjG0XMSYfREREEmPuIca2CxEREakVKx9ERERSY+lDhMkHERGRxHi1ixjbLkRERKRWrHwQERFJjFe7iDH5ICIikhhzDzG2XYiIiKQmU9FRDYsWLYKjoyMMDQ3h4eGB48ePP3f+5s2b0bhxYxgaGqJ58+bYvXu36HlBEDB9+nTY2dnByMgI3t7eSE1NrVJMTD6IiIhqqI0bNyI0NBTh4eFISUlBy5Yt4ePjg1u3bpU7/9ixY/D398ewYcNw6tQp+Pn5wc/PD+fOnVPOmT17NhYsWIAlS5YgKSkJJiYm8PHxwcOHDysdl0wQBOGlfzot8/CxpiMg0k6Tfr2g6RCItM6i/k0kP0fhI9WsY6RftfkeHh5o27YtFi5cCAAoLS2Fg4MDxo4di88++6zM/EGDBqGgoAC7du1SjrVv3x5ubm5YsmQJBEGAvb09Jk2ahMmTJwMA7t69CxsbG8TExGDw4MGViouVDyIiIonJZKo5qqK4uBgnT56Et7e3ckxHRwfe3t5ISEgo9zUJCQmi+QDg4+OjnJ+WlobMzEzRHIVCAQ8PjwrXLA83nBIREb0iioqKUFRUJBqTy+WQy+Vl5ubk5KCkpAQ2NjaicRsbG/z999/lrp+ZmVnu/MzMTOXzT8cqmlMZNTL5MKyRP9Wrp6ioCJGRkQgLCyv3DwapnzrKy/Ri/LPx+lHV51LErEjMmDFDNBYeHo6IiAjVnEBN2HYhyRQVFWHGjBllsnSi1x3/bFB1hYWF4e7du6IjLCys3LlWVlbQ1dVFVlaWaDwrKwu2trblvsbW1va585/+uyprlofJBxER0StCLpfDzMxMdFRUPTMwMIC7uzvi4uKUY6WlpYiLi4Onp2e5r/H09BTNB4B9+/Yp5zs5OcHW1lY05969e0hKSqpwzfKwQUFERFRDhYaGIigoCG3atEG7du0QFRWFgoICBAcHAwACAwPxxhtvIDIyEgAwfvx4dO7cGXPmzEHv3r2xYcMGJCcnY+nSpQAAmUyGCRMmYNasWXBxcYGTkxOmTZsGe3t7+Pn5VTouJh9EREQ11KBBg5CdnY3p06cjMzMTbm5uiI2NVW4YTU9Ph47O/5ogXl5eWLduHb744gt8/vnncHFxwfbt2/Hmm28q50ydOhUFBQUYMWIE8vLy0LFjR8TGxsLQ0LDScdXI+3yQduCmOqLy8c8Gve6YfBAREZFaccMpERERqRWTDyIiIlIrJh9ERESkVkw+SCtERETAzc1N02EQSSo+Ph4ymQx5eXnPnefo6IioqCi1xESkCdxwSmonk8mwbds20TXh+fn5KCoqgqWlpeYCI5JYcXExbt++DRsbG8hkMsTExGDChAllkpHs7GyYmJjA2NhYM4ESSYz3+SCtYGpqClNTU02HQSQpAwODSt2Cuk6dOmqIhkhz2HZ5jXTp0gXjxo3D1KlTYWFhAVtbW9GXEeXl5SEkJAR16tSBmZkZ3n77bZw5c0a0xqxZs2BtbY1atWohJCQEn332mahdcuLECXTv3h1WVlZQKBTo3LkzUlJSlM87OjoCAPr37w+ZTKZ8/GzbZe/evTA0NCzzt8Hx48fj7bffVj7esmULmjVrBrlcDkdHR8yZM+el3yOiLl26YMyYMRgzZgwUCgWsrKwwbdo0PC0S37lzB4GBgTA3N4exsTF8fX2RmpqqfP21a9fQp08fmJubw8TEBM2aNcPu3bsBiNsu8fHxCA4Oxt27dyGTySCTyZR/Hp9tuwwZMgSDBg0Sxfjo0SNYWVlh1apVAJ7cN2TcuHGwtraGoaEhOnbsiBMnTkj8ThFVH5OP18zKlSthYmKCpKQkzJ49GzNnzsS+ffsAAAMGDMCtW7fw+++/4+TJk2jdujW6deuG27dvAwDWrl2Lr776Ct9++y1OnjyJevXqYfHixaL179+/j6CgIBw5cgSJiYlwcXFBr169cP/+fQBQ/g8xOjoaGRkZ5f4Pslu3bqhduza2bNmiHCspKcHGjRsREBAAADh58iQGDhyIwYMH488//0RERASmTZuGmJgYlb9n9PpZuXIl9PT0cPz4ccyfPx9z587FsmXLAABDhw5FcnIydu7ciYSEBAiCgF69euHRo0cAgNGjR6OoqAiHDx/Gn3/+iW+//bbcqp6XlxeioqJgZmaGjIwMZGRkYPLkyWXmBQQE4Ndff0V+fr5ybM+ePXjw4AH69+8P4MkdJ7ds2YKVK1ciJSUFzs7O8PHxUf7ZJdI6Ar02OnfuLHTs2FE01rZtW+HTTz8V/vjjD8HMzEx4+PCh6PmGDRsKP/30kyAIguDh4SGMHj1a9HyHDh2Eli1bVnjOkpISoVatWsKvv/6qHAMgbNu2TTQvPDxctM748eOFt99+W/l4z549glwuF+7cuSMIgiAMGTJE6N69u2iNKVOmCE2bNq0wFqLK6Ny5s9CkSROhtLRUOfbpp58KTZo0ES5duiQAEI4ePap8LicnRzAyMhI2bdokCIIgNG/eXIiIiCh37YMHDwoAlP8dR0dHCwqFosy8+vXrC/PmzRMEQRAePXokWFlZCatWrVI+7+/vLwwaNEgQBEHIz88X9PX1hbVr1yqfLy4uFuzt7YXZs2dX6z0gkhorH6+ZFi1aiB7b2dnh1q1bOHPmDPLz82Fpaancf2Fqaoq0tDRcuXIFAHDx4kW0a9dO9Pr/Ps7KysLw4cPh4uIChUIBMzMz5OfnIz09vUpxBgQEID4+Hv/++y+AJ1WX3r17o3bt2gCACxcuoEOHDqLXdOjQAampqSgpKanSuYj+q3379pDJZMrHnp6eSE1Nxfnz56GnpwcPDw/lc5aWlnB1dcWFCxcAAOPGjcOsWbPQoUMHhIeH4+zZsy8Vi56eHgYOHIi1a9cCAAoKCrBjxw5lFfDKlSt49OiR6M+Dvr4+2rVrp4yJSNtww+lrRl9fX/RYJpOhtLQU+fn5sLOzQ3x8fJnXPP3Ar4ygoCDk5uZi/vz5qF+/PuRyOTw9PVFcXFylONu2bYuGDRtiw4YNGDVqFLZt28aWCr0SQkJC4OPjg99++w179+5FZGQk5syZg7Fjx1Z7zYCAAHTu3Bm3bt3Cvn37YGRkhJ49e6owaiL1YuWDAACtW7dGZmYm9PT04OzsLDqsrKwAAK6urmX2aPz38dGjRzFu3Dj06tVLuRk0JydHNEdfX79S1YmAgACsXbsWv/76K3R0dNC7d2/lc02aNMHRo0fLnLtRo0bQ1dWt0s9O9F9JSUmix0/3LzVt2hSPHz8WPZ+bm4uLFy+iadOmyjEHBweMHDkSW7duxaRJk/Dzzz+Xex4DA4NK/Vnw8vKCg4MDNm7ciLVr12LAgAHKv0g0bNgQBgYGoj8Pjx49wokTJ0QxEWkTJh8EAPD29oanpyf8/Pywd+9eXL16FceOHcP//d//ITk5GQAwduxYLF++HCtXrkRqaipmzZqFs2fPisrTLi4uWL16NS5cuICkpCQEBATAyMhIdC5HR0fExcUhMzMTd+7cqTCmgIAApKSk4KuvvsL7778v+vbPSZMmIS4uDl9++SUuXbqElStXYuHCheVu2COqqvT0dISGhuLixYtYv349fvjhB4wfPx4uLi7o168fhg8fjiNHjuDMmTP44IMP8MYbb6Bfv34AgAkTJmDPnj1IS0tDSkoKDh48iCZNmpR7HkdHR+Tn5yMuLg45OTl48OBBhTENGTIES5Yswb59+5QtFwAwMTHBqFGjMGXKFMTGxuL8+fMYPnw4Hjx4gGHDhqn2jSFSFU1vOiH16dy5szB+/HjRWL9+/YSgoCBBEATh3r17wtixYwV7e3tBX19fcHBwEAICAoT09HTl/JkzZwpWVlaCqamp8NFHHwnjxo0T2rdvr3w+JSVFaNOmjWBoaCi4uLgImzdvFm2eEwRB2Llzp+Ds7Czo6ekJ9evXFwSh7IbTp9q1aycAEA4cOFDmuV9++UVo2rSpoK+vL9SrV0/47rvvqv3eED3VuXNn4ZNPPhFGjhwpmJmZCebm5sLnn3+u3IB6+/Zt4cMPPxQUCoVgZGQk+Pj4CJcuXVK+fsyYMULDhg0FuVwu1KlTR/jwww+FnJwcQRDKbjgVBEEYOXKkYGlpKQAQwsPDBUEQyvyZEQRBOH/+vABAqF+/vmgzrCAIQmFhoTB27FjByspKkMvlQocOHYTjx4+r/s0hUhHe4ZReSvfu3WFra4vVq1drOhQilejSpQvc3Nx4e3MiCXHDKVXagwcPsGTJEvj4+EBXVxfr16/H/v37lfcJISIiqgwmH1RpMpkMu3fvxldffYWHDx/C1dUVW7Zsgbe3t6ZDIyKiVwjbLkRERKRWvNqFiIiI1IrJBxEREakVkw8iIiJSKyYfREREpFZMPoheQzExMVX6zh4iIlVi8kGkYUOHDoVMJoNMJoOBgQGcnZ0xc+ZMPH78WLJzDho0CJcuXarUXCYqRKRqvM8HkRbo2bMnoqOjUVRUhN27d2P06NHQ19dHWFiYaF5xcTEMDAxe+nxGRkZlvnOHiEhdWPkg0gJyuRy2traoX78+Ro0aBW9vb+zcuRNDhw6Fn58fvvrqK9jb28PV1RUAcP36dQwcOBC1a9eGhYUF+vXrh6tXrwIA9u7dC0NDQ+Tl5YnOMX78eLz99tsAylYzzpw5g65du6JWrVowMzODu7s7kpOTER8fj+DgYNy9e1dZnYmIiAAA3LlzB4GBgTA3N4exsTF8fX2Rmpoq9VtFRDUAkw8iLWRkZITi4mIAQFxcHC5evIh9+/Zh165dePToEXx8fFCrVi388ccfOHr0KExNTdGzZ08UFxejW7duqF27NrZs2aJcr6SkBBs3bhR9G+qzAgICULduXZw4cQInT57EZ599Bn19fXh5eSEqKgpmZmbIyMhARkaG8puDhw4diuTkZOzcuRMJCQkQBAG9evXCo0ePpH+DiOiVxrYLkRYRBAFxcXHYs2cPxo4di+zsbJiYmGDZsmXKdsuaNWtQWlqKZcuWQSaTAQCio6NRu3ZtxMfHo0ePHhg8eDDWrVun/Er1uLg45OXl4b333iv3vOnp6ZgyZQoaN24MAHBxcVE+p1AoIJPJYGtrqxxLTU3Fzp07cfToUXh5eQEA1q5dCwcHB2zfvh0DBgxQ/ZtDRDUGKx9EWmDXrl0wNTWFoaEhfH19MWjQIGV7o3nz5qJ9HmfOnMHly5dRq1YtmJqawtTUFBYWFnj48CGuXLkC4EklIz4+Hv/++y+AJ4lB7969K9w4GhoaipCQEHh7e+Obb75RrlORCxcuQE9PDx4eHsoxS0tLuLq64sKFCy/xThDR64DJB5EW6Nq1K06fPo3U1FQUFhZi5cqVMDExAQDlv5/Kz8+Hu7s7Tp8+LTouXbqEIUOGAADatm2Lhg0bYsOGDSgsLMS2bdsqbLkAQEREBP766y/07t0bBw4cQNOmTbFt2zbpfmAieq2x7UKkBUxMTODs7Fypua1bt8bGjRthbW0NMzOzCucFBARg7dq1qFu3LnR0dNC7d+/nrtuoUSM0atQIEydOhL+/P6Kjo9G/f38YGBigpKRENLdJkyZ4/PgxkpKSlG2X3NxcXLx4EU2bNq3Uz0FEry9WPoheMQEBAbCyskK/fv3wxx9/IC0tDfHx8Rg3bhxu3LghmpeSkoKvvvoK77//PuRyebnrFRYWYsyYMYiPj8e1a9dw9OhRnDhxAk2aNAEAODo6Ij8/H3FxccjJycGDBw/g4uKCfv36Yfjw4Thy5AjOnDmDDz74AG+88Qb69eunlveBiF5dTD6IXjHGxsY4fPgw6tWrh3fffRdNmjTBsGHD8PDhQ1ElxNnZGe3atcPZs2ef23LR1dVFbm4uAgMD0ahRIwwcOBC+vr6YMWMGAMDLywsjR47EoEGDUKdOHcyePRvAk02u7u7ueOedd+Dp6QlBELB7927o6+tL+wYQ0StPJgiCoOkgiIiI6PXBygcRERGpFZMPIiIiUismH0RERKRWTD6IiIhIrZh8EBERkVox+SAiIiK1YvJBREREasXkg4iIiNSKyQcRERGpFZMPIiIiUismH0RERKRWTD6IiIhIrf4fkDIY20is1ewAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passo 5: Testar o Modelo com Novas Frases"
      ],
      "metadata": {
        "id": "zHPv86lTUUPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 5: Testar o Modelo com Novas Frases\n",
        "\n",
        "# utilizando o modelo treinado\n",
        "def prever_sentimento(modelo, tokenizer, max_seq_len, frase_nova, mapeamento_sentimento):\n",
        "    \"\"\"\n",
        "    Prevê o sentimento de uma nova frase.\n",
        "    \"\"\"\n",
        "    # Converter a frase para sequência numérica\n",
        "    sequencia_numerica = tokenizer.texts_to_sequences([frase_nova])\n",
        "\n",
        "    # Se a frase tem palavras desconhecidas, o tokenizer pode retornar uma lista vazia ou valores 0\n",
        "    if not sequencia_numerica:\n",
        "        print(f\"Aviso: a frase '{frase_nova}' contém apenas palavras desconhecidas.\")\n",
        "        return \"Desconhecido\"  # Ou outra indicação\n",
        "\n",
        "    sequencia_numerica = sequencia_numerica[0]  # Pega a primeira (e única) sequência\n",
        "\n",
        "    # Padronizar o comprimento da sequência de entrada\n",
        "    sequencia_padded = pad_sequences([sequencia_numerica], maxlen=max_seq_len, padding='post')\n",
        "\n",
        "    # Fazer a previsão (probabilidade)\n",
        "    probabilidade_positiva = modelo.predict(sequencia_padded, verbose=0)[0][0]\n",
        "\n",
        "    # Inverter o mapeamento para obter o nome do sentimento\n",
        "    mapeamento_inverso = {v: k for k, v in mapeamento_sentimento.items()}\n",
        "\n",
        "    # Classificar com base no limiar de 0.5\n",
        "    if probabilidade_positiva >= 0.5:\n",
        "        return mapeamento_inverso[1]  # 'positivo'\n",
        "    else:\n",
        "        return mapeamento_inverso[0]  # 'negativo'\n",
        "\n",
        "\n",
        "# Testar o modelo com novas frases\n",
        "print(\"\\n--- Testando Modelo LSTM com Novas Frases ---\")\n",
        "\n",
        "frase_nova_1 = \"gostei muito do filme, excelente!\"\n",
        "sentimento_1 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_1, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_1}' -> Sentimento previsto: {sentimento_1}\")\n",
        "\n",
        "frase_nova_2 = \"odiei o livro, muito entediante\"\n",
        "sentimento_2 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_2, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_2}' -> Sentimento previsto: {sentimento_2}\")\n",
        "\n",
        "frase_nova_3 = \"a aula de pln é ótima\"\n",
        "sentimento_3 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_3, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_3}' -> Sentimento previsto: {sentimento_3}\")\n",
        "\n",
        "frase_nova_4 = \"o atendimento foi péssimo\"\n",
        "sentimento_4 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_4, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_4}' -> Sentimento previsto: {sentimento_4}\")\n",
        "\n",
        "frase_nova_5 = \"esse produto não vale a pena, é caro\"\n",
        "sentimento_5 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_5, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_5}' -> Sentimento previsto: {sentimento_5}\")\n",
        "\n",
        "frase_nova_6 = \"o filme é legal\"  # Frase curta e ambígua para um modelo pequeno\n",
        "sentimento_6 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_6, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_6}' -> Sentimento previsto: {sentimento_6}\")\n",
        "\n",
        "frase_nova_7 = \"isso é horrível, que tristeza\"\n",
        "sentimento_7 = prever_sentimento(modelo_lstm, tokenizer, max_len, frase_nova_7, mapeamento_sentimento)\n",
        "print(f\"Frase: '{frase_nova_7}' -> Sentimento previsto: {sentimento_7}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEw-XvehUW1T",
        "outputId": "86d5c4f4-0a15-42bb-c9f9-37b5a0485bac"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testando Modelo LSTM com Novas Frases ---\n",
            "Frase: 'gostei muito do filme, excelente!' -> Sentimento previsto: negativo\n",
            "Frase: 'odiei o livro, muito entediante' -> Sentimento previsto: negativo\n",
            "Frase: 'a aula de pln é ótima' -> Sentimento previsto: negativo\n",
            "Frase: 'o atendimento foi péssimo' -> Sentimento previsto: positivo\n",
            "Frase: 'esse produto não vale a pena, é caro' -> Sentimento previsto: negativo\n",
            "Frase: 'o filme é legal' -> Sentimento previsto: negativo\n",
            "Frase: 'isso é horrível, que tristeza' -> Sentimento previsto: negativo\n"
          ]
        }
      ]
    }
  ]
}
